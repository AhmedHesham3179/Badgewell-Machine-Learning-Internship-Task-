# -*- coding: utf-8 -*-
"""Spam Filter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HRn8eI-rsr3YciDjhzkwisXCwUGdW3-l

# Loading dataset

The first task is to read data from .csv file.
"""

import pandas as pd
data = pd.read_csv("spambase.csv")
data.head()

"""Selecting features and target"""

X = data.iloc[:, :-1]
y = data.iloc[:, -1]

"""# Data transformations

Standardization

We scale features in range from 0 t0 1.
"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler(copy=True, with_mean=True, with_std=True)
X = scaler.fit_transform(X)

print('X \n' , X[:10])
print('y \n' , y[:10])

"""Split data

Split the data into training and testing sets with 8:2 ratio
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=44, shuffle =True)

print('X_train shape is ' , X_train.shape)
print('X_test shape is ' , X_test.shape)
print('y_train shape is ' , y_train.shape)
print('y_test shape is ' , y_test.shape)

"""# Explantory Data Analysis

nominal {0,1} class attribute of type spam denotes whether the e-mail was considered spam (1) or not (0)
"""

spam_or_not = data["Spam"]
spam_or_not.value_counts()
spam_or_not.value_counts().plot(radius=1.2, kind="pie", autopct='%1.1f%%', pctdistance=0.5, colors=["blue", "red"])

"""39.4% of e-mails considered spam e-mails

# Model traning

# 1 - Logistic regression model

Import Libraries
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import roc_curve
from sklearn.metrics import auc

"""Applying LogisticRegression Model"""

LogisticRegressionModel = LogisticRegression()
LogisticRegressionModel.fit(X_train, y_train)

"""Calculating Prediction"""

y_pred = LogisticRegressionModel.predict(X_test)
y_pred_prob = LogisticRegressionModel.predict_proba(X_test)
print('Predicted Value for LogisticRegressionModel is : ' , y_pred[:1])

"""Calculating Confusion Matrix"""

CM = confusion_matrix(y_test, y_pred)
print('Confusion Matrix is : \n', CM)

"""drawing confusion matrix"""

sns.heatmap(CM, center = True)
plt.show()

"""Calculating Accuracy Score  : ((TP + TN) / float(TP + TN + FP + FN))"""

AccScore = accuracy_score(y_test, y_pred, normalize=False)
print('Accuracy Score is : ', AccScore)

"""Calculating Area Under the Curve"""

fprValue2, tprValue2, thresholdsValue2 = roc_curve(y_test,y_pred)
AUCValue = auc(fprValue2, tprValue2)
print('AUC Value  : ', AUCValue)

"""Ploting the (ROC Curve)"""

plt.title('Receiver Operating Characteristic (The ROC cruve)')
plt.plot(fprValue2, tprValue2, 'b', label = 'AUC = %0.2f' % AUCValue)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')

"""# 2 - SVC Model

Import Libraries
"""

from sklearn.svm import SVC

"""Applying SVC Model"""

SVCModel = SVC(kernel= 'rbf',# it can be also linear,poly,sigmoid,precomputed
               max_iter=1000,C=1.0,gamma='auto')
SVCModel.fit(X_train, y_train)

"""Calculating Prediction"""

y_pred = SVCModel.predict(X_test)
print('Predicted Value for SVCModel is : ' , y_pred[:1])

"""Calculating Confusion Matrix"""

CM = confusion_matrix(y_test, y_pred)
print('Confusion Matrix is : \n', CM)

"""drawing confusion matrix"""

sns.heatmap(CM, center = True)
plt.show()

"""Calculating Accuracy Score : ((TP + TN) / float(TP + TN + FP + FN))"""

AccScore = accuracy_score(y_test, y_pred, normalize=False)
print('Accuracy Score is : ', AccScore)

"""Calculating Area Under the Curve"""

fprValue2, tprValue2, thresholdsValue2 = roc_curve(y_test,y_pred)
AUCValue = auc(fprValue2, tprValue2)
print('AUC Value  : ', AUCValue)

"""Ploting the (ROC Curve)"""

plt.title('Receiver Operating Characteristic (The ROC cruve)')
plt.plot(fprValue2, tprValue2, 'b', label = 'AUC = %0.2f' % AUCValue)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')

"""# 3 - Decision Tree Classifier

Import Libraries
"""

from sklearn.tree import DecisionTreeClassifier

"""Applying DecisionTreeClassifier Model"""

DecisionTreeClassifierModel = DecisionTreeClassifier(criterion='gini',max_depth=3,random_state=33) #criterion can be entropy
DecisionTreeClassifierModel.fit(X_train, y_train)

"""Calculating Prediction"""

y_pred = DecisionTreeClassifierModel.predict(X_test)
y_pred_prob = DecisionTreeClassifierModel.predict_proba(X_test)
print('Predicted Value for DecisionTreeClassifierModel is : ' , y_pred[:1])

"""Calculating Confusion Matrix"""

CM = confusion_matrix(y_test, y_pred)
print('Confusion Matrix is : \n', CM)

"""drawing confusion matrix"""

sns.heatmap(CM, center = True)
plt.show()

"""Calculating Accuracy Score  : ((TP + TN) / float(TP + TN + FP + FN))"""

AccScore = accuracy_score(y_test, y_pred, normalize=False)
print('Accuracy Score is : ', AccScore)

"""Calculating Area Under the Curve"""

fprValue2, tprValue2, thresholdsValue2 = roc_curve(y_test,y_pred)
AUCValue = auc(fprValue2, tprValue2)
print('AUC Value  : ', AUCValue)

"""Ploting the (ROC Curve)"""

plt.title('Receiver Operating Characteristic (The ROC cruve)')
plt.plot(fprValue2, tprValue2, 'b', label = 'AUC = %0.2f' % AUCValue)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')

"""# 4 - Random Forest Classifier Model

Import Libraries
"""

from sklearn.ensemble import RandomForestClassifier

"""Applying RandomForestClassifier Model"""

RandomForestClassifierModel = RandomForestClassifier(criterion = 'gini',n_estimators=100,max_depth=2,random_state=33) #criterion can be also : entropy 
RandomForestClassifierModel.fit(X_train, y_train)

"""Calculating Prediction"""

y_pred = RandomForestClassifierModel.predict(X_test)
y_pred_prob = RandomForestClassifierModel.predict_proba(X_test)
print('Predicted Value for RandomForestClassifierModel is : ' , y_pred[:1])

"""Calculating Confusion Matrix"""

CM = confusion_matrix(y_test, y_pred)
print('Confusion Matrix is : \n', CM)

"""drawing confusion matrix"""

sns.heatmap(CM, center = True)
plt.show()

"""Calculating Accuracy Score  : ((TP + TN) / float(TP + TN + FP + FN))"""

AccScore = accuracy_score(y_test, y_pred, normalize=False)
print('Accuracy Score is : ', AccScore)

"""Calculating Area Under the Curve"""

fprValue2, tprValue2, thresholdsValue2 = roc_curve(y_test,y_pred)
AUCValue = auc(fprValue2, tprValue2)
print('AUC Value  : ', AUCValue)

"""Ploting the (ROC Curve)"""

plt.title('Receiver Operating Characteristic (The ROC cruve)')
plt.plot(fprValue2, tprValue2, 'b', label = 'AUC = %0.2f' % AUCValue)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')

"""# 5 - Gradient Boosting Classifier Model

Import Libraries
"""

from sklearn.ensemble import GradientBoostingClassifier

"""Applying GradientBoostingClassifier Model"""

GBCModel = GradientBoostingClassifier(n_estimators=100,max_depth=3,random_state=33) 
GBCModel.fit(X_train, y_train)

"""Calculating Prediction"""

y_pred = GBCModel.predict(X_test)
y_pred_prob = GBCModel.predict_proba(X_test)
print('Predicted Value for GBCModel is : ' , y_pred[:1])

"""Calculating Confusion Matrix"""

CM = confusion_matrix(y_test, y_pred)
print('Confusion Matrix is : \n', CM)

"""drawing confusion matrix"""

sns.heatmap(CM, center = True)
plt.show()

"""Calculating Accuracy Score  : ((TP + TN) / float(TP + TN + FP + FN))"""

AccScore = accuracy_score(y_test, y_pred, normalize=False)
print('Accuracy Score is : ', AccScore)

"""Calculating Area Under the Curve"""

fprValue2, tprValue2, thresholdsValue2 = roc_curve(y_test,y_pred)
AUCValue = auc(fprValue2, tprValue2)
print('AUC Value  : ', AUCValue)

"""Ploting the (ROC Curve)"""

plt.title('Receiver Operating Characteristic (The ROC cruve)')
plt.plot(fprValue2, tprValue2, 'b', label = 'AUC = %0.2f' % AUCValue)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')

"""# 6 - KNeighbors Classifier Model

Import Libraries
"""

from sklearn.neighbors import KNeighborsClassifier

"""Applying KNeighborsClassifier Model"""

KNNClassifierModel = KNeighborsClassifier(n_neighbors= 5,weights ='uniform', # it can be distance
                                          algorithm='auto') # it can be ball_tree, kd_tree,brute
KNNClassifierModel.fit(X_train, y_train)

"""Calculating Prediction"""

y_pred = KNNClassifierModel.predict(X_test)
y_pred_prob = KNNClassifierModel.predict_proba(X_test)
print('Predicted Value for KNNClassifierModel is : ' , y_pred[:1])

"""Calculating Confusion Matrix"""

CM = confusion_matrix(y_test, y_pred)
print('Confusion Matrix is : \n', CM)

"""drawing confusion matrix"""

sns.heatmap(CM, center = True)
plt.show()

"""Calculating Accuracy Score  : ((TP + TN) / float(TP + TN + FP + FN))"""

AccScore = accuracy_score(y_test, y_pred, normalize=False)
print('Accuracy Score is : ', AccScore)

"""Calculating Area Under the Curve"""

fprValue2, tprValue2, thresholdsValue2 = roc_curve(y_test,y_pred)
AUCValue = auc(fprValue2, tprValue2)
print('AUC Value  : ', AUCValue)

"""Ploting the (ROC Curve)"""

plt.title('Receiver Operating Characteristic (The ROC cruve)')
plt.plot(fprValue2, tprValue2, 'b', label = 'AUC = %0.2f' % AUCValue)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')

"""# 7 - GaussianNB Model

Import Libraries
"""

from sklearn.naive_bayes import GaussianNB

"""Applying GaussianNB Model"""

GaussianNBModel = GaussianNB()
GaussianNBModel.fit(X_train, y_train)

"""Calculating Prediction"""

y_pred = GaussianNBModel.predict(X_test)
y_pred_prob = GaussianNBModel.predict_proba(X_test)
print('Predicted Value for GaussianNBModel is : ' , y_pred[:1])

"""Calculating Confusion Matrix"""

CM = confusion_matrix(y_test, y_pred)
print('Confusion Matrix is : \n', CM)

"""drawing confusion matrix"""

sns.heatmap(CM, center = True)
plt.show()

"""Calculating Accuracy Score  : ((TP + TN) / float(TP + TN + FP + FN))"""

AccScore = accuracy_score(y_test, y_pred, normalize=False)
print('Accuracy Score is : ', AccScore)

"""Calculating Area Under the Curve"""

fprValue2, tprValue2, thresholdsValue2 = roc_curve(y_test,y_pred)
AUCValue = auc(fprValue2, tprValue2)
print('AUC Value  : ', AUCValue)

"""Ploting the (ROC Curve)"""

plt.title('Receiver Operating Characteristic (The ROC cruve)')
plt.plot(fprValue2, tprValue2, 'b', label = 'AUC = %0.2f' % AUCValue)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')

"""# Conclusion

After we analyze all the data and look at many methods of classification, we have some conclusions.
1- As we said in our initial data exploration, we need to find a way to our program get a classifier with an error less than 38% (because, in the worst case of telling that every email is Spam, we have 38% of error).

2- Comparing many methods, we concluded that (in this specific case) the Gradient Boosting Classifier performs better than all methods. The area under the curve of Gradient Boosting Classifier was the highest between all methods (it was around 0.94). Moreover, the accuracy score was the highest between all methods (871) and others rates were. In addition, 347 items are spam from test dataset, generally, the best method in classification.
"""